{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarizepredict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LakshmiHegde/project/blob/master/summarizepredict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR9tD4fjzlxQ",
        "colab_type": "code",
        "outputId": "30a1ac16-627b-4629-bb47-ddc88dd6235d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJskgRjP0zwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSMiJyf_01cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9Vc2cl507-l",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaRk-TlJ0nof",
        "colab_type": "code",
        "outputId": "044055ff-2368-41ab-f53f-ac2ee248eec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8aAnQ821AV7",
        "colab_type": "text"
      },
      "source": [
        "# **Reading Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QPMyW0Vzuia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(root_dir+\"Dataset/Reviews.csv\",nrows=100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "696wZWdr1SXz",
        "colab_type": "text"
      },
      "source": [
        "# **Drop duplicates and NA values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-upMW8JR0hs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)#dropping na"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qgg4eXy1agX",
        "colab_type": "code",
        "outputId": "e49459a9-5595-4170-9af6-f9a0171f857c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 88421 entries, 0 to 99999\n",
            "Data columns (total 10 columns):\n",
            "Id                        88421 non-null int64\n",
            "ProductId                 88421 non-null object\n",
            "UserId                    88421 non-null object\n",
            "ProfileName               88421 non-null object\n",
            "HelpfulnessNumerator      88421 non-null int64\n",
            "HelpfulnessDenominator    88421 non-null int64\n",
            "Score                     88421 non-null int64\n",
            "Time                      88421 non-null int64\n",
            "Summary                   88421 non-null object\n",
            "Text                      88421 non-null object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 7.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enua_vdv1jCB",
        "colab_type": "text"
      },
      "source": [
        "Here is the dictionary that we will use for expanding the contractions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fplscSSa1cZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRpV2K3Y1pDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMRcz8Fn2Zx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#call the function\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAEHxHfZ2r1C",
        "colab_type": "code",
        "outputId": "b8f92e25-094b-4276-941d-0d4bc7449408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "cleaned_text[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
              " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
              " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
              " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
              " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wquTCvgb2yaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#call the function\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGw5XEWd20Zs",
        "colab_type": "code",
        "outputId": "5545b425-f06d-46d4-e373-f6dba5ae828e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "cleaned_summary[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good quality dog food',\n",
              " 'not as advertised',\n",
              " 'delight says it all',\n",
              " 'cough medicine',\n",
              " 'great taffy',\n",
              " 'nice taffy',\n",
              " 'great just as good as the expensive brands',\n",
              " 'wonderful tasty taffy',\n",
              " 'yay barley',\n",
              " 'healthy dog food']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isZoRpQu22vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF4DnhF_2_mM",
        "colab_type": "text"
      },
      "source": [
        "# **Drop empty rows**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXv_-lto265B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pyAq0-Z2-23",
        "colab_type": "code",
        "outputId": "5ecbcbbf-0d2a-453a-c7e0-f0fae9a2be0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j9MZeJIsptJ+AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Woxnks3GoU",
        "colab_type": "code",
        "outputId": "7ab227c0-de1e-48ff-c098-8bc62c4a7579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cnt=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=8):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_summary']))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9424907471335922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ6qjGH63LJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_text_len=30\n",
        "max_summary_len=8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azt8g_xi3NcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7JX0BoS3Tfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFVW7o8o3WSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnue7YKa3bx-",
        "colab_type": "text"
      },
      "source": [
        "# **Tokenizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RNxjv843nLW",
        "colab_type": "text"
      },
      "source": [
        "Text Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_0Hvl343ZpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhsjumWc3w2t",
        "colab_type": "text"
      },
      "source": [
        "# **Rarewords and its coverage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFiKToGU3uMl",
        "colab_type": "code",
        "outputId": "fa5744fa-dac7-4f18-fe33-f32d0464e621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 66.12339930151339\n",
            "Total Coverage of rare words: 2.953684513790566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHwAfuLr357W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLZKa1eO3_cp",
        "colab_type": "code",
        "outputId": "58434754-935e-41cf-f16a-e6d097785bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_voc"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8440"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXU73bNy4BKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkGVdGV54DwB",
        "colab_type": "code",
        "outputId": "2b9abd32-3fa2-4d3f-af1f-42bb0e7cc3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 78.12740675541863\n",
            "Total Coverage of rare words: 5.3921899389571895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMrZZ_Qb4G7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g2loFXA4KEw",
        "colab_type": "code",
        "outputId": "92113104-c1df-48d1-db5f-90826ffff6b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_tokenizer.word_counts['sostok'],len(y_tr)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42453, 42453)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSnwh_B74MQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2nSay_04Q8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SbUZC0g4UEx",
        "colab_type": "code",
        "outputId": "c24b5a76-6346-4444-a363-95f2559ed08c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 30, 100)      844000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    198900      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 1989)   1195389     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,823,389\n",
            "Trainable params: 4,823,389\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tG9w9I_4a-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBKzM7gN4ewc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G4JcfY74gvF",
        "colab_type": "code",
        "outputId": "e67d39ed-4bf1-43ec-885a-eb6da1faa9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "\n",
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 41346 samples, validate on 4588 samples\n",
            "Epoch 1/50\n",
            "41346/41346 [==============================] - 64s 2ms/sample - loss: 2.8176 - val_loss: 2.6109\n",
            "Epoch 2/50\n",
            "41346/41346 [==============================] - 55s 1ms/sample - loss: 2.5078 - val_loss: 2.4240\n",
            "Epoch 3/50\n",
            "41346/41346 [==============================] - 55s 1ms/sample - loss: 2.3496 - val_loss: 2.3002\n",
            "Epoch 4/50\n",
            "41346/41346 [==============================] - 55s 1ms/sample - loss: 2.2522 - val_loss: 2.2495\n",
            "Epoch 5/50\n",
            "41346/41346 [==============================] - 55s 1ms/sample - loss: 2.1854 - val_loss: 2.1914\n",
            "Epoch 6/50\n",
            "41346/41346 [==============================] - 56s 1ms/sample - loss: 2.1345 - val_loss: 2.1598\n",
            "Epoch 7/50\n",
            "41346/41346 [==============================] - 57s 1ms/sample - loss: 2.0921 - val_loss: 2.1397\n",
            "Epoch 8/50\n",
            "41346/41346 [==============================] - 56s 1ms/sample - loss: 2.0548 - val_loss: 2.1151\n",
            "Epoch 9/50\n",
            "41346/41346 [==============================] - 56s 1ms/sample - loss: 2.0213 - val_loss: 2.1071\n",
            "Epoch 10/50\n",
            "41346/41346 [==============================] - 56s 1ms/sample - loss: 1.9915 - val_loss: 2.0867\n",
            "Epoch 11/50\n",
            "41346/41346 [==============================] - 54s 1ms/sample - loss: 1.9643 - val_loss: 2.0736\n",
            "Epoch 12/50\n",
            "41346/41346 [==============================] - 54s 1ms/sample - loss: 1.9382 - val_loss: 2.0605\n",
            "Epoch 13/50\n",
            "41346/41346 [==============================] - 54s 1ms/sample - loss: 1.9149 - val_loss: 2.0534\n",
            "Epoch 14/50\n",
            "41346/41346 [==============================] - 54s 1ms/sample - loss: 1.8919 - val_loss: 2.0592\n",
            "Epoch 15/50\n",
            "41346/41346 [==============================] - 54s 1ms/sample - loss: 1.8734 - val_loss: 2.0470\n",
            "Epoch 16/50\n",
            "41346/41346 [==============================] - 54s 1ms/sample - loss: 1.8515 - val_loss: 2.0395\n",
            "Epoch 17/50\n",
            "41346/41346 [==============================] - 54s 1ms/sample - loss: 1.8324 - val_loss: 2.0345\n",
            "Epoch 18/50\n",
            "41346/41346 [==============================] - 53s 1ms/sample - loss: 1.8144 - val_loss: 2.0351\n",
            "Epoch 19/50\n",
            "41346/41346 [==============================] - 54s 1ms/sample - loss: 1.7964 - val_loss: 2.0384\n",
            "Epoch 00019: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff8D-hAj4kMS",
        "colab_type": "code",
        "outputId": "1808f2b4-ede4-4406-d935-a5ccd81e3467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G813qCi37S1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLqJAxV77VKh",
        "colab_type": "text"
      },
      "source": [
        "# **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgif4vKA7aTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaLPGEqZ7f16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb5FHwqv7o-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noe7tPJlFLcO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9mtdvQe7rgI",
        "colab_type": "code",
        "outputId": "1b575789-f6af-4fa1-9dfc-b0b639276587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for i in range(0,1):\n",
        "    print(x_tr[i])\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 299  576 1490 1491 6123 3967  322   40 4524  116  530    7   10  429\n",
            "  220    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "Review: gave caffeine shakes heart anxiety attack plus tastes unbelievably bad stick coffee tea soda thanks \n",
            "Original summary: hour \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbedd0M27yE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str= \"medicine, archaeology, nature  if its interesting news, youll find it here. Stories like these may not always be the ones atop your news feed, but chances are theyre the ones youll actually want to read. Whether its stories of weird animals, grisly crimes, interstellar drama, or the just plain unbelievable, these are the most interesting news articles youll find anywhere.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJLeur9EEYM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_s = text_cleaner(str,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM-mhCmyElZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "818d3b92-d3f6-4046-e15e-d2e5924ff798"
      },
      "source": [
        "c_s"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'medicine archaeology nature interesting news find stories like may always ones atop news feed chances ones actually want read whether stories weird animals grisly crimes interstellar drama plain unbelievable interesting news articles find anywhere'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9T9sO8xEnJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tk = Tokenizer(num_words=tot_cnt-cnt)\n",
        "tk.fit_on_texts(c_s)\n",
        "t= tk.texts_to_sequences(c_s)\n",
        "t=pad_sequences(t, maxlen=max_text_len,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsD1CVpII5nA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc6b96a6-9d24-44b3-e61f-94b8b673be67"
      },
      "source": [
        "tk"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x7f330023d9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO0yPVPrI7lQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8d9e5c97-bc9e-43f3-af2a-b0db8681df77"
      },
      "source": [
        "t"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14,  0,  0, ...,  0,  0,  0],\n",
              "       [ 1,  0,  0, ...,  0,  0,  0],\n",
              "       [10,  0,  0, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 1,  0,  0, ...,  0,  0,  0],\n",
              "       [ 6,  0,  0, ...,  0,  0,  0],\n",
              "       [ 1,  0,  0, ...,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s13q0BCPIk3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "289755c8-61e1-43ae-b853-280c5e26bec0"
      },
      "source": [
        "print(\"Predicted summary:\",decode_sequence(t.reshape(1,max_text_len)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-711650a98416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 7410 into shape (1,30)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9ntT3QkIvgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a0deb864-93e2-4595-cf64-0315f274f234"
      },
      "source": [
        "t"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14,  0,  0, ...,  0,  0,  0],\n",
              "       [ 1,  0,  0, ...,  0,  0,  0],\n",
              "       [10,  0,  0, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 1,  0,  0, ...,  0,  0,  0],\n",
              "       [ 6,  0,  0, ...,  0,  0,  0],\n",
              "       [ 1,  0,  0, ...,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6WwmDcwKZ0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "d2c07211-a04b-461b-c1cd-712b325171f0"
      },
      "source": [
        "predict = model.predict(t)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-c829ebd5adbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 716\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    717\u001b[0m     return predict_loop(\n\u001b[1;32m    718\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2471\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    527\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    530\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[14,  0,  0, ...,  0,  0,  0],\n       [ 1,  0,  0, ...,  0,  0,  0],\n       [10,  0,  0, ...,  0,  0,  0],\n       ...,\n       [ 1,  0,  0, ...,  0,  0,  0],\n       [ 6,  0,  0, ...,  0,  0,  0..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln-4fUKUKhVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}