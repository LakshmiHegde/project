{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summaryvalues.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LakshmiHegde/project/blob/master/summaryvalues.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMJhpHqcwTPz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bb5cf9c-4ed2-4b6e-b92c-a0fcc523e439"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-07nOH4fwaK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ZOOFpQwkvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgvBvKIhwm2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ff5676ad-5b88-47ce-c362-ff88393c1ead"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUphlLKRwo8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(root_dir+\"Dataset/Reviews.csv\",nrows=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBbmat7owsf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)#dropping na"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc5J2p-7wuRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "ca615b06-ba6e-4566-fbbf-b281f5c87275"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 49 entries, 0 to 49\n",
            "Data columns (total 10 columns):\n",
            "Id                        49 non-null int64\n",
            "ProductId                 49 non-null object\n",
            "UserId                    49 non-null object\n",
            "ProfileName               49 non-null object\n",
            "HelpfulnessNumerator      49 non-null int64\n",
            "HelpfulnessDenominator    49 non-null int64\n",
            "Score                     49 non-null int64\n",
            "Time                      49 non-null int64\n",
            "Summary                   49 non-null object\n",
            "Text                      49 non-null object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 4.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qtNbcTAwwGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjcVJZucwzz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "        print(tokens)\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wUvDsu3w4ko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "e7d5fff3-bcee-48be-b09f-b818dcad0321"
      },
      "source": [
        "#call the function\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0))"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bought', 'several', 'vitality', 'canned', 'dog', 'food', 'products', 'found', 'good', 'quality', 'product', 'looks', 'like', 'stew', 'processed', 'meat', 'smells', 'better', 'labrador', 'finicky', 'appreciates', 'product', 'better']\n",
            "['product', 'arrived', 'labeled', 'jumbo', 'salted', 'peanuts', 'peanuts', 'actually', 'small', 'sized', 'unsalted', 'sure', 'error', 'vendor', 'intended', 'represent', 'product', 'jumbo']\n",
            "['confection', 'around', 'centuries', 'light', 'pillowy', 'citrus', 'gelatin', 'nuts', 'case', 'filberts', 'cut', 'tiny', 'squares', 'liberally', 'coated', 'powdered', 'sugar', 'tiny', 'mouthful', 'heaven', 'chewy', 'flavorful', 'highly', 'recommend', 'yummy', 'treat', 'familiar', 'story', 'c', 'lewis', 'lion', 'witch', 'wardrobe', 'treat', 'seduces', 'edmund', 'selling', 'brother', 'sisters', 'witch']\n",
            "['looking', 'secret', 'ingredient', 'robitussin', 'believe', 'found', 'got', 'addition', 'root', 'beer', 'extract', 'ordered', 'made', 'cherry', 'soda', 'flavor', 'medicinal']\n",
            "['great', 'taffy', 'great', 'price', 'wide', 'assortment', 'yummy', 'taffy', 'delivery', 'quick', 'taffy', 'lover', 'deal']\n",
            "['got', 'wild', 'hair', 'taffy', 'ordered', 'five', 'pound', 'bag', 'taffy', 'enjoyable', 'many', 'flavors', 'watermelon', 'root', 'beer', 'melon', 'peppermint', 'grape', 'etc', 'complaint', 'bit', 'much', 'red', 'black', 'licorice', 'flavored', 'pieces', 'kids', 'husband', 'lasted', 'two', 'weeks', 'would', 'recommend', 'brand', 'taffy', 'delightful', 'treat']\n",
            "['saltwater', 'taffy', 'great', 'flavors', 'soft', 'chewy', 'candy', 'individually', 'wrapped', 'well', 'none', 'candies', 'stuck', 'together', 'happen', 'expensive', 'version', 'fralinger', 'would', 'highly', 'recommend', 'candy', 'served', 'beach', 'themed', 'party', 'everyone', 'loved']\n",
            "['taffy', 'good', 'soft', 'chewy', 'flavors', 'amazing', 'would', 'definitely', 'recommend', 'buying', 'satisfying']\n",
            "['right', 'mostly', 'sprouting', 'cats', 'eat', 'grass', 'love', 'rotate', 'around', 'wheatgrass', 'rye']\n",
            "['healthy', 'dog', 'food', 'good', 'digestion', 'also', 'good', 'small', 'puppies', 'dog', 'eats', 'required', 'amount', 'every', 'feeding']\n",
            "['know', 'cactus', 'tequila', 'unique', 'combination', 'ingredients', 'flavour', 'hot', 'sauce', 'makes', 'one', 'kind', 'picked', 'bottle', 'trip', 'brought', 'back', 'home', 'us', 'totally', 'blown', 'away', 'realized', 'simply', 'could', 'find', 'anywhere', 'city', 'bummed', 'magic', 'internet', 'case', 'sauce', 'ecstatic', 'love', 'hot', 'sauce', 'mean', 'really', 'love', 'hot', 'sauce', 'want', 'sauce', 'tastelessly', 'burns', 'throat', 'grab', 'bottle', 'tequila', 'picante', 'gourmet', 'de', 'inclan', 'realize', 'taste', 'never', 'want', 'use', 'sauce', 'thank', 'personal', 'incredible', 'service']\n",
            "['one', 'boys', 'needed', 'lose', 'weight', 'put', 'food', 'floor', 'chubby', 'guy', 'protein', 'rich', 'product', 'food', 'higher', 'skinny', 'boy', 'jump', 'higher', 'food', 'sits', 'going', 'stale', 'really', 'go', 'food', 'chubby', 'boy', 'losing', 'ounce', 'week']\n",
            "['cats', 'happily', 'eating', 'felidae', 'platinum', 'two', 'years', 'got', 'new', 'bag', 'shape', 'food', 'different', 'tried', 'new', 'food', 'first', 'put', 'bowls', 'bowls', 'sit', 'full', 'kitties', 'touch', 'food', 'noticed', 'similar', 'reviews', 'related', 'formula', 'changes', 'past', 'unfortunately', 'need', 'find', 'new', 'food', 'cats', 'eat']\n",
            "['good', 'flavor', 'came', 'securely', 'packed', 'fresh', 'delicious', 'love', 'twizzlers']\n",
            "['strawberry', 'twizzlers', 'guilty', 'pleasure', 'yummy', 'six', 'pounds', 'around', 'son']\n",
            "['daughter', 'loves', 'twizzlers', 'shipment', 'six', 'pounds', 'really', 'hit', 'spot', 'exactly', 'would', 'expect', 'six', 'packages', 'strawberry', 'twizzlers']\n",
            "['love', 'eating', 'good', 'watching', 'tv', 'looking', 'movies', 'sweet', 'like', 'transfer', 'zip', 'lock', 'baggie', 'stay', 'fresh', 'take', 'time', 'eating']\n",
            "['satisfied', 'twizzler', 'purchase', 'shared', 'others', 'enjoyed', 'definitely', 'ordering']\n",
            "['twizzlers', 'strawberry', 'childhood', 'favorite', 'candy', 'made', 'lancaster', 'pennsylvania', 'candies', 'inc', 'one', 'oldest', 'confectionery', 'firms', 'united', 'states', 'subsidiary', 'hershey', 'company', 'company', 'established', 'young', 'smylie', 'also', 'make', 'apple', 'licorice', 'twists', 'green', 'color', 'blue', 'raspberry', 'licorice', 'twists', 'like', 'alli', 'keep', 'dry', 'cool', 'place', 'recommended', 'put', 'fridge', 'according', 'guinness', 'book', 'records', 'longest', 'licorice', 'twist', 'ever', 'made', 'measured', 'feet', 'weighted', 'pounds', 'made', 'candies', 'inc', 'record', 'breaking', 'twist', 'became', 'guinness', 'world', 'record', 'july', 'product', 'kosher', 'thank']\n",
            "['candy', 'delivered', 'fast', 'purchased', 'reasonable', 'price', 'home', 'bound', 'unable', 'get', 'store', 'perfect']\n",
            "['husband', 'twizzlers', 'addict', 'bought', 'many', 'times', 'amazon', 'government', 'employees', 'living', 'overseas', 'cannot', 'get', 'country', 'assigned', 'always', 'fresh', 'tasty', 'packed', 'well', 'arrive', 'timely', 'manner']\n",
            "['bought', 'husband', 'currently', 'overseas', 'loves', 'apparently', 'staff', 'likes', 'also', 'generous', 'amounts', 'twizzlers', 'ounce', 'bag', 'well', 'worth', 'price', 'twizzlers', 'strawberry', 'ounce', 'bags']\n",
            "['remember', 'buying', 'candy', 'kid', 'quality', 'dropped', 'years', 'still', 'superb', 'product', 'disappointed']\n",
            "['love', 'candy', 'weight', 'watchers', 'cut', 'back', 'still', 'craving']\n",
            "['lived', 'us', 'yrs', 'miss', 'twizzlers', 'go', 'back', 'visit', 'someone', 'visits', 'always', 'stock', 'say', 'yum', 'sell', 'mexico', 'faithful', 'buyer', 'often', 'able', 'buy', 'right']\n",
            "['product', 'received', 'advertised', 'twizzlers', 'strawberry', 'ounce', 'bags']\n",
            "['candy', 'red', 'flavor', 'plan', 'chewy', 'would', 'never', 'buy']\n",
            "['glad', 'amazon', 'carried', 'batteries', 'hard', 'time', 'finding', 'elsewhere', 'unique', 'size', 'need', 'garage', 'door', 'opener', 'great', 'deal', 'price']\n",
            "['got', 'mum', 'diabetic', 'needs', 'watch', 'sugar', 'intake', 'father', 'simply', 'chooses', 'limit', 'unnecessary', 'sugar', 'intake', 'one', 'sweet', 'tooth', 'loved', 'toffees', 'would', 'never', 'guess', 'sugar', 'free', 'great', 'eat', 'pretty', 'much', 'guilt', 'free', 'impressed', 'ordered', 'take', 'office', 'eat', 'instead', 'snacking', 'sugary', 'sweets', 'excellent']\n",
            "['never', 'huge', 'coffee', 'fan', 'however', 'mother', 'purchased', 'little', 'machine', 'talked', 'trying', 'latte', 'macciato', 'coffee', 'shop', 'better', 'one', 'like', 'products', 'little', 'dolche', 'guesto', 'machine', 'super', 'easy', 'use', 'prepares', 'really', 'good', 'coffee', 'latte', 'cappuccino', 'etc', 'less', 'minute', 'would', 'recommend', 'dolce', 'gusto', 'anyone', 'good', 'price', 'getting', 'one']\n",
            "['offer', 'great', 'price', 'great', 'taste', 'thanks', 'amazon', 'selling', 'product', 'staral']\n",
            "['mccann', 'instant', 'oatmeal', 'great', 'must', 'oatmeal', 'scrape', 'together', 'two', 'three', 'minutes', 'prepare', 'escaping', 'fact', 'however', 'even', 'best', 'instant', 'oatmeal', 'nowhere', 'near', 'good', 'even', 'store', 'brand', 'oatmeal', 'requiring', 'stovetop', 'preparation', 'still', 'mccann', 'good', 'gets', 'instant', 'oatmeal', 'even', 'better', 'organic', 'natural', 'brands', 'tried', 'varieties', 'mccann', 'variety', 'pack', 'taste', 'good', 'prepared', 'microwave', 'adding', 'boiling', 'water', 'convenient', 'extreme', 'time', 'issue', 'mccann', 'use', 'actual', 'cane', 'sugar', 'instead', 'high', 'fructose', 'corn', 'syrup', 'helped', 'decide', 'buy', 'product', 'real', 'sugar', 'tastes', 'better', 'harmful', 'stuff', 'one', 'thing', 'like', 'though', 'mccann', 'use', 'thickeners', 'oats', 'plus', 'water', 'plus', 'heat', 'make', 'creamy', 'tasty', 'oatmeal', 'without', 'need', 'guar', 'gum', 'convenience', 'product', 'maybe', 'guar', 'gum', 'sitting', 'bowl', 'instant', 'mccann', 'becomes', 'thick', 'gluey']\n",
            "['good', 'instant', 'oatmeal', 'best', 'oatmeal', 'brand', 'uses', 'cane', 'sugar', 'instead', 'high', 'fructouse', 'corn', 'syrup', 'better', 'sweetness', 'doctors', 'say', 'form', 'sugar', 'better', 'great', 'cold', 'morning', 'time', 'make', 'mccann', 'steel', 'cut', 'oats', 'apple', 'cinnamon', 'best', 'maple', 'brown', 'sugar', 'regular', 'good', 'plus', 'require', 'doctoring', 'actually', 'tell', 'three', 'flavors', 'apart']\n",
            "['instant', 'oatmeal', 'become', 'soggy', 'minute', 'water', 'hits', 'bowl', 'mccann', 'instant', 'oatmeal', 'holds', 'texture', 'excellent', 'flavor', 'good', 'time', 'mccann', 'regular', 'oat', 'meal', 'excellent', 'may', 'take', 'bit', 'longer', 'prepare', 'time', 'morning', 'best', 'instant', 'brand', 'ever', 'eaten', 'close', 'second', 'non', 'instant', 'variety', 'mccann', 'instant', 'irish', 'oatmeal', 'variety', 'pack', 'regular', 'apples', 'cinnamon', 'maple', 'brown', 'sugar', 'count', 'boxes']\n",
            "['mccann', 'instant', 'irish', 'oatmeal', 'variety', 'pack', 'regular', 'apples', 'cinnamon', 'maple', 'brown', 'sugar', 'count', 'boxes', 'fan', 'mccann', 'steel', 'cut', 'oats', 'thought', 'would', 'give', 'instant', 'variety', 'try', 'found', 'hardy', 'meal', 'sweet', 'great', 'folks', 'like', 'need', 'food', 'palatable', 'easily', 'digestible', 'fiber', 'make', 'bloat']\n",
            "['us', 'celiac', 'disease', 'product', 'lifesaver', 'could', 'better', 'getting', 'almost', 'half', 'price', 'grocery', 'health', 'food', 'store', 'love', 'mccann', 'instant', 'oatmeal', 'flavors', 'thanks', 'abby']\n",
            "['else', 'need', 'know', 'oatmeal', 'instant', 'expensive', 'kroger', 'store', 'brand', 'oatmeal', 'maybe', 'little', 'tastier', 'better', 'texture', 'something', 'still', 'oatmeal', 'mm', 'convenient']\n",
            "['visiting', 'friend', 'nate', 'morning', 'coffee', 'came', 'storage', 'room', 'suggested', 'try', 'use', 'stash', 'sometimes', 'nate', 'dose', 'give', 'chance', 'say', 'ended', 'trying', 'apple', 'cinn', 'found', 'tastefull', 'made', 'water', 'powdered', 'milk', 'goes', 'good', 'j', 'coffee', 'slice', 'toast', 'ready', 'take', 'world', 'day', 'least', 'jerry', 'reith']\n",
            "['ordered', 'wife', 'reccomended', 'daughter', 'almost', 'every', 'morning', 'likes', 'flavors', 'happy', 'happy', 'mccann', 'instant', 'irish', 'oatmeal', 'variety', 'pack', 'regular', 'apples', 'cinnamon', 'maple', 'brown', 'sugar', 'count', 'boxes']\n",
            "['variety', 'packs', 'taste', 'great', 'every', 'morning', 'cents', 'per', 'meal', 'understand', 'everyone', 'earth', 'buying', 'stuff', 'maple', 'brown', 'sugar', 'terrific', 'followed', 'apples', 'cinnamon', 'followed', 'regular', 'get', 'tired', 'ole', 'thing', 'taste', 'great', 'boil', 'water', 'small', 'pot', 'empty', 'packet', 'bowl', 'pour', 'boiling', 'water', 'watch', 'expand', 'x', 'size', 'taste', 'really', 'good', 'takes', 'minutes', 'prepare', 'sure', 'everyone', 'earth', 'convenient', 'healthy', 'quick', 'excellent', 'quality', 'extremely', 'cheap']\n",
            "['mccann', 'makes', 'oatmeal', 'every', 'oatmeal', 'connoisseur', 'whether', 'one', 'likes', 'raw', 'pellet', 'state', 'cooks', 'half', 'hour', 'sloth', 'addled', 'instant', 'done', 'microwave', 'three', 'minutes', 'good', 'sure', 'beauty', 'instant', 'variety', 'available', 'different', 'flavors', 'well', 'regular', 'variety', 'pack', 'allows', 'different', 'tastes', 'explored', 'well', 'giving', 'chance', 'experience', 'difference', 'mccann', 'well', 'known', 'oatmeals', 'personally', 'like', 'mccann', 'cooks', 'thicker', 'body', 'top', 'brand', 'america', 'apples', 'cinnamon', 'though', 'tends', 'little', 'liquidy', 'may', 'want', 'experiment', 'amount', 'water', 'add', 'watt', 'microwave', 'oatmeal', 'cooks', 'one', 'minute', 'twenty', 'seven', 'seconds', 'also', 'watch', 'get', 'handle', 'much', 'time', 'water', 'use', 'bad', 'thing', 'consider', 'bad', 'thing', 'offering', 'buy', 'lot', 'end', 'six', 'ten', 'count', 'boxes', 'good', 'whole', 'family', 'oatmeal', 'eaters', 'single', 'person', 'alone', 'well', 'love', 'oatmeal']\n",
            "['mccann', 'oatmeal', 'every', 'morning', 'ordering', 'amazon', 'able', 'save', 'almost', 'per', 'box', 'great', 'product', 'tastes', 'great', 'healthy']\n",
            "['mccann', 'oatmeal', 'good', 'quality', 'choice', 'favorite', 'apples', 'cinnamon', 'find', 'none', 'overly', 'sugary', 'good', 'hot', 'breakfast', 'minutes', 'excellent']\n",
            "['really', 'like', 'mccann', 'steel', 'cut', 'oats', 'find', 'cook', 'often', 'tastes', 'much', 'better', 'grocery', 'store', 'brands', 'convenient', 'anything', 'keeps', 'eating', 'oatmeal', 'regularly', 'good', 'thing']\n",
            "['seems', 'little', 'wholesome', 'supermarket', 'brands', 'somewhat', 'mushy', 'quite', 'much', 'flavor', 'either', 'pass', 'muster', 'kids', 'probably', 'buy']\n",
            "['good', 'oatmeal', 'like', 'apple', 'cinnamon', 'best', 'though', 'would', 'follow', 'directions', 'package', 'since', 'always', 'comes', 'soupy', 'taste', 'could', 'since', 'like', 'oatmeal', 'really', 'thick', 'add', 'milk', 'top']\n",
            "['flavors', 'good', 'however', 'see', 'differce', 'oaker', 'oats', 'brand', 'mushy']\n",
            "['really', 'like', 'maple', 'brown', 'sugar', 'flavor', 'regular', 'fine', 'brown', 'sugar', 'added', 'apples', 'cinnamon', 'flavor', 'ok', 'quick', 'easy', 'satisfying', 'breakfast', 'order', 'brand', 'variety', 'get', 'maple', 'brown', 'sugar']\n",
            "['stuff', 'buy', 'big', 'box', 'stores', 'nothing', 'healthy', 'carbs', 'sugars', 'save', 'money', 'get', 'something', 'least', 'taste']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwDO4U6zxC8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a4805dd1-cd9c-410d-ffff-e90ecb77cf77"
      },
      "source": [
        "cleaned_text[:5]"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
              " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
              " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
              " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
              " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lskSBSZayH-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#call the function\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3jW_gP0yR8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "580e3d8c-b0e5-46aa-9dd2-b362b94e754b"
      },
      "source": [
        "cleaned_summary[:10]"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good quality dog food',\n",
              " 'not as advertised',\n",
              " 'delight says it all',\n",
              " 'cough medicine',\n",
              " 'great taffy',\n",
              " 'nice taffy',\n",
              " 'great just as good as the expensive brands',\n",
              " 'wonderful tasty taffy',\n",
              " 'yay barley',\n",
              " 'healthy dog food']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZjDvP5QyT3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--eDrqcIyeYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32708b32-da25-419f-9edd-6e2124c25191"
      },
      "source": [
        "data['cleaned_summary'][0]"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good quality dog food'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g43m8kIy0QP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZRnIvBHy6Je",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "f23cf24e-fb5d-4a75-d522-191cd2ba131c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDSPr2YbzFHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10d54f3b-e8e1-4c7c-e0e5-fe9312b73f82"
      },
      "source": [
        "cnt=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=9):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_summary']))"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9387755102040817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEK_QR4kz2ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_summary_len=9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_0YYxjJz8L_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c19ab58-500b-4f7b-aefd-371938c87a5f"
      },
      "source": [
        "cnt=0\n",
        "for i in data['cleaned_text']:\n",
        "    if(len(i.split())<=50):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_text']))"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8775510204081632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U1Z9ICE0Acq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "max_text_len=50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l_gJFGf0oW1",
        "colab_type": "text"
      },
      "source": [
        "selecting reviews and summary of length below threshold defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBmfMUGN0U0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3nUnqCA0Yfv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a0c6929-7337-4613-dbbb-f2a627cbc233"
      },
      "source": [
        "len(cleaned_text)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZbPBt7R0ayw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e015b76e-7303-4d94-f261-1d189eac2cec"
      },
      "source": [
        "len(cleaned_summary)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HObqMmNQ0jbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "short_text=[]\n",
        "short_summary=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO6vRHRS2NWW",
        "colab_type": "text"
      },
      "source": [
        "dataframe is created with short text and summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3WXaXR90y9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "\n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kV0obWc01cO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "082d377f-c0a7-4d59-ca00-9ee55953366a"
      },
      "source": [
        "len(short_text)"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NGSpHIm08tL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d372dcec-eadf-4b62-ec0a-6d33d147535d"
      },
      "source": [
        "len(short_summary)"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsfOIBlR0-1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d8f5e009-e922-472a-facd-1e0038cbc275"
      },
      "source": [
        "short_text[0]"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz5H5MKZ1GW5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e96ef1b1-26cd-4ab6-a4fa-cb82f419cf06"
      },
      "source": [
        "short_summary[0]"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good quality dog food'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRGuFHD01JqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba3e8687-f886-497b-a849-d7359c18f5db"
      },
      "source": [
        "short_text[40]"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stuff buy big box stores nothing healthy carbs sugars save money get something least taste'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Dlxe-21O_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ed69a8e-ff8b-435d-f6f9-1e41d56109d1"
      },
      "source": [
        "short_summary[40]"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'same stuff'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuouRFyp1caS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT9cpQBn2YZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7e27e66-2e39-4acc-9d4e-916e8b03a314"
      },
      "source": [
        "df['summary'][0]"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sostok good quality dog food eostok'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OyEjI0s2zXz",
        "colab_type": "text"
      },
      "source": [
        "test and validation set is created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cujz2iUx2bWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzp0xD57GLJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cb3dc069-b60a-41a6-d578-646dcf28e748"
      },
      "source": [
        "x_tr[0],x_val[0]"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('else need know oatmeal instant expensive kroger store brand oatmeal maybe little tastier better texture something still oatmeal mm convenient',\n",
              " 'got mum diabetic needs watch sugar intake father simply chooses limit unnecessary sugar intake one sweet tooth loved toffees would never guess sugar free great eat pretty much guilt free impressed ordered take office eat instead snacking sugary sweets excellent')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlJMpNgNGSEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bbb150c-d2d0-4afb-bbec-0be3f2facbd8"
      },
      "source": [
        "y_tr[0],y_val[0]"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sostok it is oatmeal eostok', 'sostok yummy eostok')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_htWyYq2yV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jsFFExl2-Pm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4b5a10db-9810-48e8-9d53-bffa0b7a56b7"
      },
      "source": [
        "x_tr[0],x_val[0]"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('else need know oatmeal instant expensive kroger store brand oatmeal maybe little tastier better texture something still oatmeal mm convenient',\n",
              " 'got mum diabetic needs watch sugar intake father simply chooses limit unnecessary sugar intake one sweet tooth loved toffees would never guess sugar free great eat pretty much guilt free impressed ordered take office eat instead snacking sugary sweets excellent')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA4Ca4gT3AnL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04093f79-ee87-4526-fae9-9b9cea435cdf"
      },
      "source": [
        "y_tr[0],y_val[0]"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sostok it is oatmeal eostok', 'sostok yummy eostok')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlP-5OjV3PYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "780e46b8-d94f-4524-f353-7a45fecf923e"
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    print('key :' , key,'value: ',value)\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "key : else value:  1\n",
            "key : need value:  2\n",
            "key : know value:  1\n",
            "key : oatmeal value:  11\n",
            "key : instant value:  4\n",
            "key : expensive value:  2\n",
            "key : kroger value:  1\n",
            "key : store value:  4\n",
            "key : brand value:  4\n",
            "key : maybe value:  1\n",
            "key : little value:  4\n",
            "key : tastier value:  1\n",
            "key : better value:  8\n",
            "key : texture value:  1\n",
            "key : something value:  2\n",
            "key : still value:  3\n",
            "key : mm value:  1\n",
            "key : convenient value:  2\n",
            "key : offer value:  1\n",
            "key : great value:  7\n",
            "key : price value:  6\n",
            "key : taste value:  3\n",
            "key : thanks value:  2\n",
            "key : amazon value:  4\n",
            "key : selling value:  2\n",
            "key : product value:  9\n",
            "key : staral value:  1\n",
            "key : good value:  14\n",
            "key : flavor value:  4\n",
            "key : came value:  2\n",
            "key : securely value:  1\n",
            "key : packed value:  2\n",
            "key : fresh value:  3\n",
            "key : delicious value:  1\n",
            "key : love value:  5\n",
            "key : twizzlers value:  9\n",
            "key : really value:  4\n",
            "key : like value:  6\n",
            "key : mccann value:  5\n",
            "key : steel value:  2\n",
            "key : cut value:  4\n",
            "key : oats value:  3\n",
            "key : find value:  1\n",
            "key : cook value:  1\n",
            "key : often value:  2\n",
            "key : tastes value:  2\n",
            "key : much value:  3\n",
            "key : grocery value:  2\n",
            "key : brands value:  2\n",
            "key : anything value:  1\n",
            "key : keeps value:  1\n",
            "key : eating value:  3\n",
            "key : regularly value:  1\n",
            "key : thing value:  1\n",
            "key : us value:  2\n",
            "key : celiac value:  1\n",
            "key : disease value:  1\n",
            "key : lifesaver value:  1\n",
            "key : could value:  2\n",
            "key : getting value:  2\n",
            "key : almost value:  3\n",
            "key : half value:  1\n",
            "key : health value:  1\n",
            "key : food value:  3\n",
            "key : flavors value:  7\n",
            "key : abby value:  1\n",
            "key : best value:  3\n",
            "key : uses value:  1\n",
            "key : cane value:  1\n",
            "key : sugar value:  5\n",
            "key : instead value:  1\n",
            "key : high value:  1\n",
            "key : fructouse value:  1\n",
            "key : corn value:  1\n",
            "key : syrup value:  1\n",
            "key : sweetness value:  1\n",
            "key : doctors value:  1\n",
            "key : say value:  3\n",
            "key : form value:  1\n",
            "key : cold value:  1\n",
            "key : morning value:  4\n",
            "key : time value:  3\n",
            "key : make value:  1\n",
            "key : apple value:  3\n",
            "key : cinnamon value:  3\n",
            "key : maple value:  2\n",
            "key : brown value:  2\n",
            "key : regular value:  2\n",
            "key : plus value:  1\n",
            "key : require value:  1\n",
            "key : doctoring value:  1\n",
            "key : actually value:  2\n",
            "key : tell value:  1\n",
            "key : three value:  1\n",
            "key : apart value:  1\n",
            "key : candy value:  6\n",
            "key : weight value:  1\n",
            "key : watchers value:  1\n",
            "key : back value:  2\n",
            "key : craving value:  1\n",
            "key : though value:  1\n",
            "key : would value:  7\n",
            "key : follow value:  1\n",
            "key : directions value:  1\n",
            "key : package value:  1\n",
            "key : since value:  2\n",
            "key : always value:  3\n",
            "key : comes value:  1\n",
            "key : soupy value:  1\n",
            "key : thick value:  1\n",
            "key : add value:  1\n",
            "key : milk value:  2\n",
            "key : top value:  1\n",
            "key : confection value:  1\n",
            "key : around value:  3\n",
            "key : centuries value:  1\n",
            "key : light value:  1\n",
            "key : pillowy value:  1\n",
            "key : citrus value:  1\n",
            "key : gelatin value:  1\n",
            "key : nuts value:  1\n",
            "key : case value:  1\n",
            "key : filberts value:  1\n",
            "key : tiny value:  2\n",
            "key : squares value:  1\n",
            "key : liberally value:  1\n",
            "key : coated value:  1\n",
            "key : powdered value:  2\n",
            "key : mouthful value:  1\n",
            "key : heaven value:  1\n",
            "key : chewy value:  4\n",
            "key : flavorful value:  1\n",
            "key : highly value:  2\n",
            "key : recommend value:  5\n",
            "key : yummy value:  2\n",
            "key : treat value:  3\n",
            "key : familiar value:  1\n",
            "key : story value:  1\n",
            "key : lewis value:  1\n",
            "key : lion value:  1\n",
            "key : witch value:  2\n",
            "key : wardrobe value:  1\n",
            "key : seduces value:  1\n",
            "key : edmund value:  1\n",
            "key : brother value:  1\n",
            "key : sisters value:  1\n",
            "key : stuff value:  1\n",
            "key : buy value:  4\n",
            "key : big value:  1\n",
            "key : box value:  2\n",
            "key : stores value:  1\n",
            "key : nothing value:  1\n",
            "key : healthy value:  3\n",
            "key : carbs value:  1\n",
            "key : sugars value:  1\n",
            "key : save value:  2\n",
            "key : money value:  1\n",
            "key : get value:  3\n",
            "key : least value:  2\n",
            "key : bought value:  3\n",
            "key : husband value:  3\n",
            "key : currently value:  1\n",
            "key : overseas value:  2\n",
            "key : loves value:  2\n",
            "key : apparently value:  1\n",
            "key : staff value:  1\n",
            "key : likes value:  2\n",
            "key : also value:  2\n",
            "key : generous value:  1\n",
            "key : amounts value:  1\n",
            "key : ounce value:  3\n",
            "key : bag value:  2\n",
            "key : well value:  3\n",
            "key : worth value:  1\n",
            "key : strawberry value:  4\n",
            "key : bags value:  2\n",
            "key : satisfied value:  1\n",
            "key : twizzler value:  1\n",
            "key : purchase value:  1\n",
            "key : shared value:  1\n",
            "key : others value:  1\n",
            "key : enjoyed value:  1\n",
            "key : definitely value:  2\n",
            "key : ordering value:  2\n",
            "key : received value:  1\n",
            "key : advertised value:  1\n",
            "key : delivered value:  1\n",
            "key : fast value:  1\n",
            "key : purchased value:  2\n",
            "key : reasonable value:  1\n",
            "key : home value:  1\n",
            "key : bound value:  1\n",
            "key : unable value:  1\n",
            "key : perfect value:  1\n",
            "key : seems value:  1\n",
            "key : wholesome value:  1\n",
            "key : supermarket value:  1\n",
            "key : somewhat value:  1\n",
            "key : mushy value:  2\n",
            "key : quite value:  1\n",
            "key : either value:  1\n",
            "key : pass value:  1\n",
            "key : muster value:  1\n",
            "key : kids value:  2\n",
            "key : probably value:  1\n",
            "key : right value:  2\n",
            "key : mostly value:  1\n",
            "key : sprouting value:  1\n",
            "key : cats value:  1\n",
            "key : eat value:  1\n",
            "key : grass value:  1\n",
            "key : rotate value:  1\n",
            "key : wheatgrass value:  1\n",
            "key : rye value:  1\n",
            "key : daughter value:  2\n",
            "key : shipment value:  1\n",
            "key : six value:  3\n",
            "key : pounds value:  2\n",
            "key : hit value:  1\n",
            "key : spot value:  1\n",
            "key : exactly value:  1\n",
            "key : expect value:  1\n",
            "key : packages value:  1\n",
            "key : got value:  2\n",
            "key : wild value:  1\n",
            "key : hair value:  1\n",
            "key : taffy value:  5\n",
            "key : ordered value:  3\n",
            "key : five value:  1\n",
            "key : pound value:  1\n",
            "key : enjoyable value:  1\n",
            "key : many value:  2\n",
            "key : watermelon value:  1\n",
            "key : root value:  2\n",
            "key : beer value:  2\n",
            "key : melon value:  1\n",
            "key : peppermint value:  1\n",
            "key : grape value:  1\n",
            "key : etc value:  2\n",
            "key : complaint value:  1\n",
            "key : bit value:  1\n",
            "key : red value:  2\n",
            "key : black value:  1\n",
            "key : licorice value:  1\n",
            "key : flavored value:  1\n",
            "key : pieces value:  1\n",
            "key : lasted value:  1\n",
            "key : two value:  1\n",
            "key : weeks value:  1\n",
            "key : delightful value:  1\n",
            "key : addict value:  1\n",
            "key : times value:  1\n",
            "key : government value:  1\n",
            "key : employees value:  1\n",
            "key : living value:  1\n",
            "key : cannot value:  1\n",
            "key : country value:  1\n",
            "key : assigned value:  1\n",
            "key : tasty value:  1\n",
            "key : arrive value:  1\n",
            "key : timely value:  1\n",
            "key : manner value:  1\n",
            "key : watching value:  1\n",
            "key : tv value:  1\n",
            "key : looking value:  2\n",
            "key : movies value:  1\n",
            "key : sweet value:  1\n",
            "key : transfer value:  1\n",
            "key : zip value:  1\n",
            "key : lock value:  1\n",
            "key : baggie value:  1\n",
            "key : stay value:  1\n",
            "key : take value:  2\n",
            "key : every value:  3\n",
            "key : able value:  2\n",
            "key : per value:  1\n",
            "key : soft value:  2\n",
            "key : amazing value:  1\n",
            "key : buying value:  2\n",
            "key : satisfying value:  1\n",
            "key : wife value:  1\n",
            "key : reccomended value:  1\n",
            "key : happy value:  2\n",
            "key : irish value:  1\n",
            "key : variety value:  1\n",
            "key : pack value:  1\n",
            "key : apples value:  1\n",
            "key : count value:  1\n",
            "key : boxes value:  1\n",
            "key : arrived value:  1\n",
            "key : labeled value:  1\n",
            "key : jumbo value:  2\n",
            "key : salted value:  1\n",
            "key : peanuts value:  2\n",
            "key : small value:  2\n",
            "key : sized value:  1\n",
            "key : unsalted value:  1\n",
            "key : sure value:  1\n",
            "key : error value:  1\n",
            "key : vendor value:  1\n",
            "key : intended value:  1\n",
            "key : represent value:  1\n",
            "key : never value:  2\n",
            "key : huge value:  1\n",
            "key : coffee value:  5\n",
            "key : fan value:  1\n",
            "key : however value:  2\n",
            "key : mother value:  1\n",
            "key : machine value:  2\n",
            "key : talked value:  1\n",
            "key : trying value:  2\n",
            "key : latte value:  2\n",
            "key : macciato value:  1\n",
            "key : shop value:  1\n",
            "key : one value:  2\n",
            "key : products value:  2\n",
            "key : dolche value:  1\n",
            "key : guesto value:  1\n",
            "key : super value:  1\n",
            "key : easy value:  1\n",
            "key : use value:  2\n",
            "key : prepares value:  1\n",
            "key : cappuccino value:  1\n",
            "key : less value:  1\n",
            "key : minute value:  1\n",
            "key : dolce value:  1\n",
            "key : gusto value:  1\n",
            "key : anyone value:  1\n",
            "key : guilty value:  1\n",
            "key : pleasure value:  1\n",
            "key : son value:  1\n",
            "key : visiting value:  1\n",
            "key : friend value:  1\n",
            "key : nate value:  2\n",
            "key : storage value:  1\n",
            "key : room value:  1\n",
            "key : suggested value:  1\n",
            "key : try value:  1\n",
            "key : stash value:  1\n",
            "key : sometimes value:  1\n",
            "key : dose value:  1\n",
            "key : give value:  1\n",
            "key : chance value:  1\n",
            "key : ended value:  1\n",
            "key : cinn value:  1\n",
            "key : found value:  3\n",
            "key : tastefull value:  1\n",
            "key : made value:  2\n",
            "key : water value:  1\n",
            "key : goes value:  1\n",
            "key : slice value:  1\n",
            "key : toast value:  1\n",
            "key : ready value:  1\n",
            "key : world value:  1\n",
            "key : day value:  1\n",
            "key : jerry value:  1\n",
            "key : reith value:  1\n",
            "key : glad value:  1\n",
            "key : carried value:  1\n",
            "key : batteries value:  1\n",
            "key : hard value:  1\n",
            "key : finding value:  1\n",
            "key : elsewhere value:  1\n",
            "key : unique value:  1\n",
            "key : size value:  1\n",
            "key : garage value:  1\n",
            "key : door value:  1\n",
            "key : opener value:  1\n",
            "key : deal value:  1\n",
            "key : saltwater value:  1\n",
            "key : individually value:  1\n",
            "key : wrapped value:  1\n",
            "key : none value:  1\n",
            "key : candies value:  1\n",
            "key : stuck value:  1\n",
            "key : together value:  1\n",
            "key : happen value:  1\n",
            "key : version value:  1\n",
            "key : fralinger value:  1\n",
            "key : served value:  1\n",
            "key : beach value:  1\n",
            "key : themed value:  1\n",
            "key : party value:  1\n",
            "key : everyone value:  1\n",
            "key : loved value:  1\n",
            "key : plan value:  1\n",
            "key : lived value:  1\n",
            "key : yrs value:  1\n",
            "key : miss value:  1\n",
            "key : go value:  1\n",
            "key : visit value:  1\n",
            "key : someone value:  1\n",
            "key : visits value:  1\n",
            "key : stock value:  1\n",
            "key : yum value:  1\n",
            "key : sell value:  1\n",
            "key : mexico value:  1\n",
            "key : faithful value:  1\n",
            "key : buyer value:  1\n",
            "key : remember value:  1\n",
            "key : kid value:  1\n",
            "key : quality value:  2\n",
            "key : dropped value:  1\n",
            "key : years value:  1\n",
            "key : superb value:  1\n",
            "key : disappointed value:  1\n",
            "key : dog value:  3\n",
            "key : digestion value:  1\n",
            "key : puppies value:  1\n",
            "key : eats value:  1\n",
            "key : required value:  1\n",
            "key : amount value:  1\n",
            "key : feeding value:  1\n",
            "key : see value:  1\n",
            "key : differce value:  1\n",
            "key : oaker value:  1\n",
            "key : secret value:  1\n",
            "key : ingredient value:  1\n",
            "key : robitussin value:  1\n",
            "key : believe value:  1\n",
            "key : addition value:  1\n",
            "key : extract value:  1\n",
            "key : cherry value:  1\n",
            "key : soda value:  1\n",
            "key : medicinal value:  1\n",
            "key : several value:  1\n",
            "key : vitality value:  1\n",
            "key : canned value:  1\n",
            "key : looks value:  1\n",
            "key : stew value:  1\n",
            "key : processed value:  1\n",
            "key : meat value:  1\n",
            "key : smells value:  1\n",
            "key : labrador value:  1\n",
            "key : finicky value:  1\n",
            "key : appreciates value:  1\n",
            "% of rare words in vocabulary: 93.34862385321101\n",
            "Total Coverage of rare words: 76.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me158s2JGanP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "81c31721-0ae6-436d-9e9e-9f476f46d671"
      },
      "source": [
        "x_tr[0],x_val[0]\n"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('else need know oatmeal instant expensive kroger store brand oatmeal maybe little tastier better texture something still oatmeal mm convenient',\n",
              " 'got mum diabetic needs watch sugar intake father simply chooses limit unnecessary sugar intake one sweet tooth loved toffees would never guess sugar free great eat pretty much guilt free impressed ordered take office eat instead snacking sugary sweets excellent')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz0yGwnBGqm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e3efcf8-12b6-490c-9bbd-ceff231a34c3"
      },
      "source": [
        "y_tr[0],y_val[0]"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sostok it is oatmeal eostok', 'sostok yummy eostok')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1wsnW65zV0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Remember:\n",
        "\n",
        "tot_cnt gives the size of vocabulary (which means every unique words in the text)\n",
        "\n",
        "cnt gives me the no. of rare words whose count falls below threshold\n",
        "\n",
        "tot_cnt - cnt gives me the top most common words\n",
        "\n",
        "Let us define the tokenizer with top most common words for reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n3qSoLkFyGK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21bqyGq8FoI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb50c001-538e-47f4-c03d-0c1092ece105"
      },
      "source": [
        "x_tr[0]"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'else need know oatmeal instant expensive kroger store brand oatmeal maybe little tastier better texture something still oatmeal mm convenient'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROXgiw8-4Cap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz4sIv_a59v0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5d6937e5-a855-44ff-8f8f-5a71d1654326"
      },
      "source": [
        "x_tr[0]"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2, 18, 19, 20,  2, 21,  5,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmhffcm_6Kp4",
        "colab_type": "text"
      },
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05T5ZQcc6Bq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_w2kWp76lxM",
        "colab_type": "text"
      },
      "source": [
        "Let us look at the proportion rare words and its total coverage in the entire summary\n",
        "\n",
        "Here, I am defining the threshold to be 6 which means word whose count is below 6 is considered as a rare word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdOVyUuC6MeW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8a6403c1-349f-4a03-f9e5-79aa6070d856"
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 97.43589743589743\n",
            "Total Coverage of rare words: 60.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0v0AYf46rUo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Let us define the tokenizer with top most common words for summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RInwIIhV6OeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXZCW9646Uag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b60ddf8-fd0e-4fe8-b219-4552e8827b5a"
      },
      "source": [
        "y_voc"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I3ZIoGF6YVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c12218c3-9cd5-4e09-c330-d8895447b08e"
      },
      "source": [
        "y_tokenizer.word_counts['sostok']\n",
        "len(y_tr)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edp0hssA7FbG",
        "colab_type": "text"
      },
      "source": [
        "Here, I am deleting the rows that contain only START and END tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzEjNU3O6deo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxBDpvbM7KEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBrWqlbC7Xjt",
        "colab_type": "text"
      },
      "source": [
        "Return Sequences = True: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
        "\n",
        "Return State = True: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
        "\n",
        "Initial State: This is used to initialize the internal states of the LSTM for the first timestep\n",
        "\n",
        "Stacked LSTM: Stacked LSTM has multiple layers of LSTM stacked on top of each other. This leads to a better representation of the sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thLAxgkU7bp5",
        "colab_type": "text"
      },
      "source": [
        "Here, we are building a 3 stacked LSTM for the encoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Njo3YZD7MJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "94b1389a-b200-45ae-b9d2-9dd91dfccf49"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNVI7i3R7fN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 300\n",
        "embedding_dim=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4cwp73F7hWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6eCto0T7jt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "09664cdc-9e39-45aa-8690-9b84261c1ea5"
      },
      "source": [
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2UIOwlW7sS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HjXO_Oz7yjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-TAr2jl742W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDG-eV7X78Tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ab716f8a-d2bf-444f-9b1a-298d62fb1f34"
      },
      "source": [
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVzAZMo8Jsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "40123e24-db7d-4308-8493-b5a445eb6c64"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 50, 100)      3000        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50, 300), (N 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    300         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 50, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 3)      1803        concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,590,203\n",
            "Trainable params: 2,590,203\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "merSoCOJ8L9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBHv0em58TK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvJAZSD08WUB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "f4f5277e-318c-42a2-e378-1979566c53c1"
      },
      "source": [
        "\n",
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=80,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 36 samples, validate on 5 samples\n",
            "Epoch 1/80\n",
            "36/36 [==============================] - 1s 15ms/sample - loss: 3.9985e-07 - val_loss: 2.6822e-07\n",
            "Epoch 2/80\n",
            "36/36 [==============================] - 0s 13ms/sample - loss: 4.0647e-07 - val_loss: 2.6524e-07\n",
            "Epoch 3/80\n",
            "36/36 [==============================] - 0s 12ms/sample - loss: 3.3155e-07 - val_loss: 2.6524e-07\n",
            "Epoch 4/80\n",
            "36/36 [==============================] - 0s 12ms/sample - loss: 3.4562e-07 - val_loss: 2.6226e-07\n",
            "Epoch 5/80\n",
            "36/36 [==============================] - 0s 12ms/sample - loss: 3.7708e-07 - val_loss: 2.5928e-07\n",
            "Epoch 6/80\n",
            "36/36 [==============================] - 0s 12ms/sample - loss: 3.3983e-07 - val_loss: 2.5630e-07\n",
            "Epoch 7/80\n",
            "36/36 [==============================] - 0s 12ms/sample - loss: 3.4066e-07 - val_loss: 2.5630e-07\n",
            "Epoch 8/80\n",
            "36/36 [==============================] - 0s 12ms/sample - loss: 3.2534e-07 - val_loss: 2.5630e-07\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-lz83yF8b7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "4d10b477-a40f-452b-f78c-5c861cc2679f"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC3RjjHEJC3RjjHGJ/w8SU7Y+Sy0IaQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwhp7Tz381_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL73TUHu9Zoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bg5PmAL9h_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj_AWa5F93hr",
        "colab_type": "text"
      },
      "source": [
        "Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub74Wyuk9meS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqbKmbsH97hP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "08f262e2-ac4f-46d7-c41a-3d0db2174fcc"
      },
      "source": [
        "x_tr[i]\n"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  5,  9, 19, 12, 13, 18,  2,  7,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My0ERbry9_vX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a58b0e8-8346-4fbe-8fd0-3459e2eccfe7"
      },
      "source": [
        "seq2text(x_tr[i])"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'product better price store love mccann instant oatmeal flavors '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl3qBoBP-iD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae3c6300-9f46-482a-c5d2-a10e9a1043dd"
      },
      "source": [
        "seq2summary(y_tr[0])"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjAauo5M-3kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}